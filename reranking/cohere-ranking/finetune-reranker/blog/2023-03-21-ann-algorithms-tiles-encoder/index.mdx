---
title: The Tile Encoder - Exploring ANN algorithms Part 2.2
slug: ann-algorithms-tiles-enocoder
authors: [abdel]
date: 2023-03-21
tags: ['research']
image: ./img/hero.png
description: "Using the Weaviate Tile Encoder to compress vectors with Product Quantization."
---
![The Tiles Encoder - Exploring ANN algorithms Part 2.2](./img/hero.png)

<!---
This is a markdown blog post that explains the Tile encoder, an alternative to the KMeans encoder for compressing vectors with Product Quantization.
--->

In our [previous](/blog/ann-algorithms-hnsw-pq) post, we explained how to compress vectors in memory using HNSW+PQ and KMeans encoding. In this post, we present an alternative to KMeans, the Tile encoder, which is a distribution-based encoder.

<!---
The Tile encoder is an alternative to KMeans for compressing vectors with Product Quantization. It is a distribution-based encoder that doesn't need to be fit to the data, unlike KMeans.
--->

## Tile Encoder

KMeans produces a tiling over the full range of values using the centroids. Each centroid has a tile associated with it. When a new vector has to be encoded, the algorithm checks which tile it belongs to, and the vector code is set using the index of the closest found tile.

<!---
KMeans fits a tiling over the full range of values using the centroids. Each centroid has a tile associated with it. When a new vector has to be encoded, the algorithm checks which tile it belongs to, and the vector code is set using the index of the closest found tile.
--->

The Tile encoder works similarly, but it doesn’t need to be fit to the data since it leverages the fact that we know the underlying distribution of the data beforehand.

<!---
The Tile encoder works similarly, but it doesn’t need to be fit to the data since it leverages the fact that we know the underlying distribution of the data beforehand. This means that the Tile encoder can encode vectors more quickly than KMeans.
--->

## Centroid Distributions

To get a better understanding of the distribution of the centroids, let us create some illustrations with the generated centroids.

<!---
To get a better understanding of the distribution of the centroids, let us create some illustrations with the generated centroids. This will help us compare the distribution of centroids generated by KMeans and the Tile encoder.
--->

![image2](./img/image2.png)
![image3](./img/image3.png)

<!---
Fig. 2 shows the centroids generated by the KMeans and Tile encoders. Both charts show the cartesian product of the first two segments. Both encoders were fitted using 32 centroids. Above we show the centroids from KMeans. Below we show the centroids from Tile.
--->

As we can observe, both approaches generate similar results. The centroids are very dense at the origin of both axes and much more sparse as the values grow.

<!---
Both approaches generate similar results. The centroids are very dense at the origin of both axes and much more sparse as the values grow. This is because the data is more likely to be centered around the origin.
--->

It is worth mentioning that a multivariate approach would fit the data better than the cartesian product of individually built segments.

<!---
It is worth mentioning that a multivariate approach would fit the data better than the cartesian product of individually built segments. This is because the data is not independent across dimensions.
--->

To depict this, we show Figure 3.

<!---
To depict this, we show Figure 3. This figure shows the centroids generated by KMeans on the first segment including the first two dimensions. The encoder was fitted using 32 (above) and 256 (below) centroids. Centroids fit better the distribution of the data as opposed to using independent segments for each dimension when using enough centroids.
--->

![image4](./img/image4.png)
![image5](./img/image5.png)

<!---
Fig. 3 shows the centroids generated by KMeans on the first segment including the first two dimensions. The encoder was fitted using 32 (above) and 256 (below) centroids. Centroids fit better the distribution of the data as opposed to using independent segments for each dimension when using enough centroids.
--->

We are yet to extend the tile encoder to the multivariate case.

<!---
We are yet to extend the tile encoder to the multivariate case. This will allow the Tile encoder to fit the data better and improve the compression performance.
--->

Although this is not extremely difficult, it still needs some work and will be included in the near future.

<!---
Although this is not extremely difficult, it still needs some work and will be included in the near future. We have decided to publish this initial implementation so it can be tested with more data.
--->

Notice that this encoder depends on the fact that the distribution of the data is known a priori.

<!---
Notice that this encoder depends on the fact that the distribution of the data is known a priori. This means that you need to provide this information beforehand. Currently we support normal and lognormal distributions which are very common. If your data follows a different distribution, extending the code is very simple so do not hesitate to contact us.
--->

## Results of the KMeans Vs Tile encoding

In this section we present some results on the comparison of Product Quantization using KMeans vs the Tile encoder.

<!---
In this section we present some results on the comparison of Product Quantization using KMeans vs the Tile encoder. This will help us understand the performance and compression trade-offs between the two encoders.
--->

Table 1 shows a comparison of Product Quantization using KMeans and the Tile encoders.

<!---
Table 1 shows a comparison of Product Quantization using KMeans and the T
