---
title: Weaviate 1.2 release - transformer models # Title of the blog post
slug: weaviate-1-2-transformer-models # Slug for the blog post
authors: [etienne] # Author of the blog post
date: 2021-03-30 # Date of the blog post
tags: ['release'] # Tags associated with the blog post
image: ./img/hero.png # Image for the blog post
# canonical-url: https://medium.com/semi-technologies/weaviate-version-1-2-x-now-supports-transformer-models-4a12d858cce3 # Canonical URL for the blog post
# canonical-name: Medium # Canonical name for the blog post
description: "Weaviate v1.2 introduced support for transformers (DistilBERT, BERT, RoBERTa, Sentence-BERT, etc) to vectorize and semantically search through your data." # Description of the blog post
---

![Weaviate 1.2 release - transformer models](./img/hero.png)

In the v1.0 release of Weaviate ([docs](/developers/weaviate/) — [GitHub](https://github.com/weaviate/weaviate)) we introduced the concept of [modules](/developers/weaviate/concepts/modules). # Introduction to Weaviate modules

Weaviate modules are used to extend the vector database with vectorizers or functionality that can be used to query your dataset. # Explanation of Weaviate modules

With the release of Weaviate v1.2, we have introduced the use of transformers ([DistilBERT](https://arxiv.org/abs/1910.01108), [BERT](https://github.com/google-research/bert), [RoBERTa](https://arxiv.org/abs/1907.11692), Sentence-[BERT](https://arxiv.org/abs/1908.10084), etc) to vectorize and semantically search through your data. # Introduction of transformers in Weaviate v1.2

<!-- truncate -->

### Weaviate v1.2 introduction video

<div className="youtube">
    <iframe src="//www.youtube.com/embed/S4lXPPZvGPQ" frameBorder="0" allowFullScreen></iframe>
</div>

## What are transformers?
A [transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)) (e.g., [BERT](https://en.wikipedia.org/wiki/BERT_(language_model))) is a deep learning model that is used for NLP tasks. # Explanation of transformers

Within Weaviate the transformer module can be used to vectorize and query your data. # Explanation of the transformer module in Weaviate

## Getting started with out-of-the-box transformers in Weaviate
By selecting the text-module in the [Weaviate configuration tool](/developers/weaviate/installation/docker-compose#configurator), you can run Weaviate with transformers in one command. # Instructions for getting started with out-of-the-box transformers in Weaviate

You can learn more about the Weaviate transformer module [here](/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-transformers). # Link to learn more about the Weaviate transformer module

![Weaviate configurator — selecting the Transformers module](./img/configurator-demo.gif)
*Weaviate configurator — selecting the Transformers module*

## Custom transformer models
You can also use custom transformer models that are compatible with Hugging Face's `AutoModel` and `AutoTokenzier`. # Explanation of using custom transformer models in Weaviate

Learn more about using custom models in Weaviate [here](/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-transformers). # Link to learn more about using custom transformer models in Weaviate

## Q&A style questions on your own dataset answered in milliseconds
Weaviate now allows you to get to sub-50ms results by using transformers on your own data. # Explanation of Weaviate's speed with transformers

You can learn more about Weaviate’s speed in combination with transformers in [this article](https://towardsdatascience.com/a-sub-50ms-neural-search-with-distilbert-and-weaviate-4857ae390154). # Link to learn more about Weaviate's speed with transformers


import WhatNext from '/_includes/what-next.mdx'

<WhatNext />

``
