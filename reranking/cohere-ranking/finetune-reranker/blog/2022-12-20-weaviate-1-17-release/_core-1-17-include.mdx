<!-- Weaviate 1.17 release announcement -->

We are happy to announce the release of Weaviate `1.17`, which brings a set of great features, performance improvements, and fixes.

## The brief
If you like your content brief and to the point, here is the TL;DR of this release:

1. [Replication](#replication) - configure multi-node replication to improve your database resilience and performance
1. [Hybrid Search](#hybrid-search) - combine dense and sparse vectors to deliver the best of both search methods
1. [BM25](#bm25) - search your data with bm25
1. [Faster Startup and Imports](#faster-startup-and-imports) - enjoy Weaviate, that is up and running faster than ever before with more speedy data imports
1. [Other Improvements and Bug Fixes](#other-improvements-and-bug-fixes) – enjoy a more stable Weaviate experience, courtesy of fixes and improvements delivered in nine installments since 1.16.0.

Read below to learn more about each of these points in more detail.

<a name="replication"></a>
## Replication

Weaviate's `v1.17` release introduces **replication**. Replication enables you to set up your Weaviate environment in a cluster with multiple server nodes. Weaviate will automatically replicate data across nodes in the background.

### Use Cases
This enables a variety of [use cases](/developers/weaviate/concepts/replication-architecture/motivation). For example, if a Weaviate node goes down, another node can shoulder the load without losing availability or data. Data in Weaviate will thus have a **higher availability** for its users.

Secondly, Replication can improve the **throughput of read requests**, as you can use all additional nodes to spread the load of queries. Adding extra database nodes can serve more users simultaneously.

Thirdly, database replication enables **zero downtime upgrades**, because only a single node has to stop at a time while other replicas can continue serving.

A final motivation for using database replication is **regional proximity**. With Multi-DataCenter replication, you can put Weaviate servers in different locations, which can decrease latency for users spread out geographically. The Multi-DataCenter feature is not implemented yet, [but we are already working on it](https://github.com/weaviate/weaviate/issues/2436).

### Replication Design in Weaviate
Replication in Weaviate is modeled after how users typically use Weaviate. Most use cases are very-large-scale, which aim for low latency and high availability.

It is often tolerable if data is temporarily out of sync, as long as consistency is reached eventually. Keeping the [CAP Theorem](/developers/weaviate/concepts/replication-architecture/#cap-theorem) trade-offs in mind, Weaviate's replication architecture **prefers availability over consistency**.

Nevertheless, both read and write consistency will become [fully tunable](/developers/weaviate/concepts/replication-architecture/consistency) from `v1.18` (read consistency is partly tunable from `v1.17`).

Weaviate has a [leaderless replication design](/developers/weaviate/concepts/replication-architecture/cluster-architecture), so there is no distinction between primary and secondary nodes, thereby removing all single points of failures.

### Roadmap
With `v1.17`, the foundations of replication are built into Weaviate. In `v1.18` and later releases, more features will be added:

| Weaviate version | Expected release | Feature |
| --- | --- | --- |
| `v1.17` | Live | * Leaderless Replication<br />* Tunable Read Consistency for Get-by-ID requests |
| `v1.18` | Feb 2023 | * Tunable Write Consistency<br />* Tunable Read Consistency for all requests<br />* Repairs – Read-Repairs or Background/Async Repairs |
| TBD | TBD | * Multi-Data center replication (upvote it [here](https://github.com/weaviate/weaviate/issues/2436)) |

### Learn More
To learn more, visit the documentation pages for [Replication Architecture](/developers/weaviate/concepts/replication-architecture) and/or [Usage](/developers/weaviate/configuration/replication), where all concepts are explained in detail, supported by illustrations!

<a name="hybrid-search"></a>
## Hybrid Search

Hybrid search is a search functionality that **combines** the best features of both keyword-based search algorithms with vector search techniques. In hybrid search, sparse and dense vectors are used to represent the meaning and context of search queries and documents. Sparse embeddings are generated from models like [BM25](https://en.wikipedia.org/wiki/Okapi_BM25) and [SPLADE](https://arxiv.org/abs/2107.05720). Dense embeddings are generated from machine learning models like [GloVe](https://text2vec.org/glove.html) and [Transformers](https://huggingface.co/docs/transformers/index).

Using both sparse and dense search methods combines the power of keyword matching with contextual semantics. For example, in the query "How to catch an Alaskan Pollock?", the semantic meaning of "catch" is revealed to be related to fishing from the context; this is where dense vectors thrive. Sparse methods on their own would not be able to associate "catch" with fishing any differently from catching a baseball or a cold. On the other hand, sparse methods can capture specific entities such as "Alaskan Pollock". This query illustrates an example where hybrid search combines the best of both sparse and dense vectors.

### Hybrid Search Query
Here is an example of how to run a hybrid search query in GraphQL:

