---
title: Make Real-Time AI a Reality with Weaviate + Confluent
slug: confluent-and-weaviate
authors: [shukri]
date: 2023-09-26
tags: ['integrations', 'how-to']
image: ./img/hero.png
description: "Learn how to build an application using Weaviate and Confluent"
---

<video width="100%" autoplay loop controls>
  <source src={confluentVideo} type="video/mp4" />
Your browser does not support the video tag.
</video>

<!-- truncate -->

Today, we’re excited to announce our new integration with [Confluent Cloud](https://www.confluent.io/confluent-cloud/?utm_campaign=tm.pmm_cd.2023_partner_cwc_weaviate_generic&utm_source=weaviate&utm_medium=partnerref). Weaviate users now have simple access to data streams from across their entire business to build a real-time, contextual, and trustworthy knowledge base fueling their AI applications.

> “With our new integration with Confluent Cloud, Weaviate is taking a giant leap forward in empowering businesses to build AI applications that are not just smart, but also real-time and context-aware. Now, you can seamlessly tap into data streams from every corner of your enterprise, creating a continuously updated knowledge base that lets your AI systems respond to the world as it happens.”
>
>
— Etienne Dilocker, Chief Technology Officer, Weaviate

## High-value, trusted AI applications require real-time data
Real-time AI needs real-time data from everywhere. The promise of real-time AI is only unlocked when models have all the fresh contextual data they need to respond just in time with the most accurate, relevant, and helpful information. However, building these real-time data connections across on-prem, multicloud, public, and private cloud environments for AI use cases is non-trivial.

Traditional data integration and processing tools are batch-based and inflexible, creating an untenable number of tightly coupled point-to-point connections that are hard to scale and lack governance. As a result, data made available is stale and of low fidelity. This introduces unavoidable latency into the AI application and may outright block implementation altogether. The difficulty in gaining access to high-quality, ready-to-use, contextual and trustworthy data in real-time is hindering developer agility and the pace of AI innovation.

## Confluent’s data streaming platform fuels Weaviate with real-time data
With Confluent, Weaviate users can break down data silos, promote data reusability, improve engineering agility, and foster greater trust throughout their organization. This allows more teams to securely and confidently unlock the full potential of all their data with Weaviate. Confluent enables organizations to make real-time contextual inferences on an astonishing amount of data by bringing well curated, trustworthy streaming data to hybrid search and generative AI applications.

With easy access to data streams from across their entire business, Weaviate users can now:

* **Create a real-time knowledge base:**
Build a shared source of real-time truth for all your operational and analytical data, no matter where it lives for sophisticated model building and fine-tuning. Think business competitive analysis dashboards that are updated with latest market news updates.
* **Bring real-time context at query time:**
Convert raw data into meaningful chunks with real-time enrichment and continually update your embedding databases for your GenAI use cases. Think real-time filtering based on region, demographics, personas in online shopping, etc.
* **Build governed, secured, and trusted AI:**
Establish data lineage, quality and traceability, providing all your teams with a clear understanding of data origin, movement, transformations and usage.
* **Experiment, scale and innovate faster:**
Reduce innovation friction as new AI apps and models become available. Decouple data from your data science tools and production AI apps to test and build faster.

## Weaviate and Confluent enable simple development of real-time AI applications
Our new Confluent integration enables all your teams to tap into a continuously enriched real-time knowledge base, so they can quickly scale and build AI-enabled applications using trusted data streams. Let’s take a look at how it works:

![Figure1Dark](./img/fig1-dark.png#gh-dark-mode-only)
![Figure1Light](./img/fig1-light.png#gh-light-mode-only)

The integration architecture is designed to be both robust and straightforward, ensuring a seamless flow of real-time data from Confluent Cloud to Weaviate Cloud Services.

1. **Kafka Topic in Confluent Cloud:** The journey begins in Confluent Cloud, where you create a fully managed Kafka topic that holds the data you wish to stream into Weaviate.
2. **Spark Cluster with confluent-connector Library:** Next, you'll spin up a Spark cluster loaded with our specialized Confluent-Connector library. This cluster acts as the data processing engine that facilitates the data flow between Confluent Cloud and Weaviate.
3. **Streaming DataFrame in Spark:** Within the Spark environment, you'll create a streaming DataFrame. This DataFrame is configured to continuously pull the data from your designated Kafka topic in Confluent Cloud.
4. **DataFrame to Weaviate via Confluent-Connector:** Finally, the streaming DataFrame is written into Weaviate using the [Confluent-Connector](https://github.com/weaviate/confluent-connector/tree/main). This ensures that your Weaviate knowledge base is always up-to-date, enriched with real-time data streaming from Confluent.

By connecting these components, you create a powerful, real-time data pipeline that enables your teams to build AI-enabled applications with a continuously enriched and trustworthy knowledge base.

## Getting Started
We'll be using code snippets from a Python notebook, which assumes you're running a local Spark cluster in standalone mode. For a comprehensive, end-to-end walkthrough, you can access the full Python notebook [here](https://github.com/weaviate/confluent-connector/blob/main/notebooks/02_demo_confluent
