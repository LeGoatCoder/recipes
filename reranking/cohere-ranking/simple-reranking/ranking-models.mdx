# Title: Ranking Models for Better Search

"""
Whether searching to present information to a human or a large language model,
quality matters. One of the low hanging fruit strategies to improve search
quality are ranking models.
"""

# Published a blog post on Cross Encoder Ranking
# (/blog/cross-encoders-as-reranker)

# Visualization of combining Bi-Encoders and Cross-Encoders
# (fishing example: coarse-grained retrieval and manual inspection)

# March, Bob van Luijt discussed "AI and The Future of Search"
# (https://twitter.com/cohereai/status/1636396916157079554)

# Hybrid Search: combining contextual semantics from vector search
# and keyword matching from BM25 scoring

# Ranking model: takes [query, candidate document] pair as input
# and further reasons about the relevance of these results
# without specialized training

# Categories of ranking models:
# 1. Cross Encoders
# 2. Metadata Rankers
# 3. Score Rankers

# 1. Cross Encoders: content-based re-ranking
# using pre-trained models, such as those available on Sentence Transformers

# Weaviate Podcast Search dataset example
# using Cross Encoder for re-ranking results

# 2. Metadata Rankers: context-based re-rankers
# using symbolic features to rank relevance
# typically in the context of recommendation

# Weaviate enables storing metadata features about objects
# such as `price`, or `color`

# 3. Score Rankers: using classifiers or regression models
# to score and detect content, acting as guardrails for generative models

# Each of these ranking models have particular use cases
# but the lines between these models are blurring
# with new trends such as translating tabular metadata features into text
# to facilitate transfer learning from transformers pre-trained on text

# Ranking for Retrieval-Augmented Generation
# A lot of the recent successes of vector search
# can be attributed to their effectiveness as a tool for Large Language Models

# Shi et al. have published "Large Language Models are easily distracted
# by irrelevant context", highlighting how problematic bad precision in search
# can be for retrieval-augmented generation

# Recent developments in LLM agent tooling
# are paving the way towards letting LLMs run for a while to complete complex tasks

# By ranking each handoff from search to prompt,
# we can achieve better results in each intermediate task
"""
