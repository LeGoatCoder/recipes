# Install required libraries
!pip install weaviate-client llama-index==0.8.10

# Import necessary libraries
import weaviate
from llama_index import download_loader, SimpleWebPageReader

# Initialize Weaviate client
client = weaviate.Client(
    embedded_options=weaviate.embedded.EmbeddedOptions()
)

# Test connection to Weaviate
client.schema.get()

# Define schema for BlogPost class
schema = {
   "classes": [\n",
       {\n",
           "class": "BlogPost",\n",
           "description": "Blog post from the Weaviate website.\",\n",
           "vectorizer": "text2vec-openai",\n",
           "properties": [\n",
               {\n",
                  "name": "content",\n",
                  "dataType": ["text"],\n",
                  "description": "Content from the blog post\",\n",
               }\n",
            ]\n",
        }\n",
    ]\n",
}

# Create schema in Weaviate
client.schema.create(schema)
print("Schema was created.")

# Load data from webpage
from llama_index import download_loader, SimpleWebPageReader
SimpleWebPageReader = download_loader("SimpleWebPageReader")
loader = SimpleWebPageReader(html_to_text=True)
blog = loader.load_data(urls=['https://weaviate.io/blog/llamaindex-and-weaviate'])

# Construct vector store
from llama_index.vector_stores import WeaviateVectorStore
from llama_index import VectorStoreIndex, StorageContext
from llama_index.storage.storage_context import StorageContext
import os
import openai

openai.api_key = 'sk-key'

vector_store = WeaviateVectorStore(weaviate_client = client, index_name="BlogPost", text_key="content")

# Setting up the storage for the embeddings
storage_context = StorageContext.from_defaults(vector_store = vector_store)

# Set up the index
index = VectorStoreIndex(blog, storage_context = storage_context)

query_engine = index.as_query_engine()

# Set up Sub Question Query Engine
from llama_index.tools import QueryEngineTool, ToolMetadata
from llama_index.query_engine import SubQuestionQueryEngine

query_engine_tools = [\n",
    QueryEngineTool(\n",
        query_engine = query_engine,\n",
        metadata = ToolMetadata(name='BlogPost', description='Blog post about the integration of LlamaIndex and Weaviate')\n",
    )\n",
]

query_engine = SubQuestionQueryEngine.from_defaults(query_engine_tools=query_engine_tools)

# Query Time
response = await query_engine.aquery('How does LlamaIndex help data indexing in Weaviate?')
print(response)
