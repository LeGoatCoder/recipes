# Import necessary libraries
import sys
import os
import time
import json
import weaviate

# Define Weaviate URL, batch size, and Sphere dataset filename
WEAVIATE_URL = 'https://loadtest.weaviate.network/'
BATCH_SIZE = 100
SPHERE_DATASET = 'sphere.100k.jsonl'  # Update this to match your filename

# Initialize Weaviate client
client = weaviate.Client(
    url=WEAVIATE_URL,
    timeout_config=600
)

# Configure batch settings
client.batch.configure(
    batch_size=BATCH_SIZE,
    dynamic=True,
    num_workers=os.cpu_count()
)

# Create 'Page' class in Weaviate with DPR model configuration
client.schema.create_class({
    "class": "Page",
    "vectorizer": "text2vec-huggingface",
    "moduleConfig": {
        "passageModel": "sentence-transformers/facebook-dpr-ctx_encoder-single-nq-base",
        "queryModel": "sentence-transformers/facebook-dpr-question_encoder-single-nq-base",
        "options": {
            "waitForModel": True,
            "useGPU": True,
            "useCache": True
        }
    },
    "properties": []
})

# Import Sphere dataset into Weaviate
start = time.time()
c = 0
with open(SPHERE_DATASET) as jsonl_file:
    with client.batch as batch:
        for jsonl in jsonl_file:
            json_parsed = json.loads(jsonl)
            batch.add_data_object({
                    'url':  json_parsed['url'],
                    'title': json_parsed['title'],
                    'raw': json_parsed['raw'],
                    'sha': json_parsed['sha']
                },
                'Page',
                json_parsed['id'],
                vector=json_parsed['vector']
            )
            c += 1
            if (c % (BATCH_SIZE * 10)) == 0:
                print('Imported', c)

end = time.time()
print('Done in', end - start)

# Make sure to update the SPHERE_DATASET property to correctly match your `.jsonl` filename.

