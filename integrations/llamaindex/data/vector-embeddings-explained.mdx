# Title: Vector Embeddings Explained

# Semantic searches are searches based on the meaning of text or the content of images. For example, a search for "wine for seafood" won't find a wine described as "good with fish", but a meaning-based search should understand the similarity and find the wine.

# Vector embeddings are the core data structure used in semantic search. They are arrays of numbers that represent the meaning of data objects, such as text or images.

# Here's how semantic search using vector embeddings works:

# 1. The vector database computes a vector embedding for each data object as it is inserted or updated into the database.
# 2. The embeddings are placed into an index for quick searches.
# 3. For each query,
#     a. a vector embedding is computed for the query.
#     b. the database finds the closest vectors to the given vector using a special algorithm.

# The quality of the search depends crucially on the quality of the model used to generate the vector embeddings, and the speed of the search depends on the performance of the vector database.

# Vector embeddings can represent the meaning of any kind of data object, such as text, images, audio, time series data, 3D models, video, or molecules.

# For example, consider the words "cat" and "kitty". Although the words are different, their vector embeddings should be similar to capture their semantic similarity.

# Here's an example of vector embeddings for the words "cat" and "kitty":

cat_vector = [1.5, -0.4, 7.2, 19.6, 3.1, ..., 20.2]
kitty_vector = [1.5, -0.4, 7.2, 19.5, 3.2, ..., 20.8]

# These two vectors have a high similarity, indicating their semantic similarity.

# Each number in a vector embedding represents a different feature of the data object. However, the exact meaning of each number is not always clear and depends on the machine learning model used to generate the vectors.

# Vector-based representation of meaning has caused a stir in recent years, with the revelation of mathematical operations between words. For example, the equation "king - man + woman â‰ˆ queen" indicates that the difference between "king" and "man" is analogous to the difference between "queen" and "woman".

# Vector embeddings can be visualized using colors and arranged next to the corresponding words. Here's an example of vector embeddings for the words "woman", "girl", "boy", and "water":

#   woman: [0.1, 0.2, 0.3, ..., 0.5]
#   girl:  [0.1, 0.2, 0.3, ..., 0.6]
#   boy:   [0.1, 0.2, 0.3, ..., 0.7]
#   water: [0.8, 0.9, 1.0, ..., 1.2]

# We can see that the vectors for "woman", "girl", and "boy" are similar to each other, while the vector for "water" is different.

# Effective vector embeddings can be generated for any kind of data object, not just words. For example, two images with similar semantics will have vectors that are close to each other in vector space.

# The distance between vectors can be calculated in multiple ways, such as the sum of the absolute differences between elements at the same position in each vector.

# Here's an example of vector embeddings for some words:

#   cat:   [1.5, -0.4, 7.2, 19.6, 20.2]
#   dog:   [1.7, -0.3, 6.9, 19.1, 21.1]
#   apple: [-5.2, 3.1, 0.2, 8.1, 3.5]
#   fruit: [-5.1, 2.9, 0.8, 7.9, 3.1]

# If we look at each of the 5 elements of the vectors, we can see that "cat" and "dog" are closer than "dog" and "apple", and "fruit" is closer to "apple" and "strawberry" than to the other words.

# Vector embeddings are generated using machine learning models, and the process of generating vector embeddings for each entity and query is the magic of vector search.

# Over the last decade, vectorization techniques for text have evolved tremendously, from word2vec to transformer models such as BERT.

# Word-level dense vector models such as word2vec generate a single vector for each word in a vocabulary, but they cannot handle words with multiple meanings or ambiguous meanings.

# Transformer models such as BERT generate contextual embeddings that take the entire input text into account, better reflecting the polysemantic nature of words.

# However, transformer models require more compute and memory resources than word-level models.

# Despite these downsides, transformer models have been successful in improving search accuracy, precision, and recall.

# Vector embeddings can be generated for various media types such as text, images, audio, and others.

# Weaviate is a vector database that supports many different vectorizer models and vectorizer service providers. You can even bring your own vectors if you already have a vectorization pipeline available.

# For example, Weaviate supports using any Hugging Face models through the `text2vec-huggingface` module, or using OpenAI or Cohere through the `text2vec-openai` or `text2vec-cohere` modules.

# Modules such as `multi2vec-clip` can convert images and text to vectors using a CLIP model.

# Regardless of the specific model or module used, the core task of vector embeddings is to represent the "meaning" of the original data as a set of numbers, which is why semantic search works so well.
