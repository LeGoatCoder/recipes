# Weaviate Import
# 
# This notebook is used to populate the `WeaviateBlogChunk` class.
# 
# 1. Run `docker-compose up -d` with the docker script in the file to start Weaviate locally on localhost:8080
# 
# 2. Make sure the `/blog` folder is in this directory (these are parsed from github.com/weaviate/weaviate-io -- feel free to drag and drop that folder in here to update the content).
# 
# 3. Run this notebook and the 1182 blog chunks will be loaded into Weaviate.

# Import Weaviate and Connect to Client
# Connect to the Weaviate instance running on localhost:8080
import weaviate
client = weaviate.Client("http://localhost:8080")

# Create Schema
# Define the schema for the `WeaviateBlogChunk` class
schema = {
   "classes": [
       {
           "class": "WeaviateBlogChunk",
           "description": "A snippet from a Weaviate blogpost.",
           "moduleConfig": {
               "text2vec-openai": {
                    "skip": False,
                    "vectorizeClassName": False,
                    "vectorizePropertyName": False
                },
                "generative-openai": {
                    "model": "gpt-3.5-turbo"
                }
           },
           "vectorIndexType": "hnsw",
           "vectorizer": "text2vec-openai",
           "properties": [
               {
                   "name": "content",
                   "dataType": ["text"],
                   "description": "The text content of the podcast clip",
                   "moduleConfig": {
                    "text2vec-transformers": {
                        "skip": False,
                        "vectorizePropertyName": False,
                        "vectorizeClassName": False
                    }
                   }
               },
               {
                   "name": "author",
                   "dataType": ["text"],
                   "description": "The author of the blog post.",
                   "moduleConfig": {
                       "text2vec-openai": {
                           "skip": True,
                           "vectorizePropertyName": False,
                           "vectorizeClassName": False
                       }
                   }
               }
           ]
       }     
   ]
}

# Create the `WeaviateBlogChunk` class in Weaviate
client.schema.create(schema)

# Functions to read, split, and chunk the blog content
import os
import re

def chunk_list(lst, chunk_size):
    """Break a list into chunks of the specified size."""
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]

def split_into_sentences(text):
    """Split text into sentences using regular expressions."""
    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)
    return [sentence.strip() for sentence in sentences if sentence.strip()]

def read_and_chunk_index_files(main_folder_path):
    """Read index.md files from subfolders, split into sentences, and chunk every 5 sentences."""
    blog_chunks = []
    for folder_name in os.listdir(main_folder_path):
        subfolder_path = os.path.join(main_folder_path, folder_name)
        if os.path.isdir(subfolder_path):
            index_file_path = os.path.join(subfolder_path, 'index.mdx')
            if os.path.isfile(index_file_path):
                with open(index_file_path, 'r', encoding='utf-8') as file:
                    content = file.read()
                    sentences = split_into_sentences(content)
                    sentence_chunks = chunk_list(sentences, 5)
                    sentence_chunks = [' '.join(chunk) for chunk in sentence_chunks]
                    blog_chunks.extend(sentence_chunks)
    return blog_chunks

# Example usage
main_folder_path = './blog'
blog_chunks = read_and_chunk_index_files(main_folder_path)

# Print the number of blog chunks
print(f"Number of blog chunks: {len(blog_chunks)}")

# Display the first blog chunk
print(f"First blog chunk:\n{blog_chunks[0]}\n")

# Configure the batch request
# Set the batch size, timeout retries, and error callback
client.batch.configure(
  batch_size=100,
  dynamic=False,
  timeout_retries=3,
  callback=weaviate.util.check_batch_result
)

# Upload blog chunks to Weaviate
# Create a data object for each blog chunk and add it to the batch request
from weaviate.util import get_valid_uuid
from uuid import uuid4
import time
start = time.time()
for idx, blog_chunk in enumerate(blog_chunks):
    data_properties = {
        "content": blog_chunk
    }
    id = get_valid_uuid(uuid4())
    with client.batch as batch:
        batch.add_data_object(
            data_properties,
            "WeaviateBlogChunk"
        )
    print(f"Uploaded {idx} documents in {time.time() - start} seconds.")
