# Weaviate `1.23` is here!

# Release highlights:
# 1. AutoPQ: Weaviate now automatically triggers the use of Product Quantization (PQ) for vector indexing.
# 2. Flat vector index + Binary Quantization: New index type for small collections, such as for multi-tenancy use cases.
# 3. `generative-anyscale`: Adds open-source large language model integration.
# 4. Performance improvements: Mean time to recovery (MMTR) is reduced and automatic resource limiting prevents out-of-memory errors.
# 5. Python client beta update: Adds `1.23` support and new features.
# 6. Minor changes: The `nodes` endpoint adds a new `minimal` output default.

# Available on WCS
# `1.23` is already available on Weaviate Cloud Services - so try it out!

# AutoPQ
# Weaviate introduced Product Quantization (PQ) earlier this year. In v1.23 we've made it easier to get started.
# PQ requires a training step. We've created AutoPQ to take care of the training for you.
# Just enable AutoPQ in your system configuration. Then, any time you enable PQ on a new collection, AutoPQ takes care of training and initializes PQ for you.

# Flat vector index + Binary Quantization
# Weaviate now supports a `flat` vector index type in addition to the existing `hnsw` index.
# The `flat` index is a single layer of disk-based references to the object vectors.
# This index type is particularly useful for multi-tenancy use cases, where each tenant's collection is relatively small.
# The `flat` index can be optionally combined with binary quantization (BQ) compression to speed up vector search.

# OSS LLM integration with `generative-anyscale`
# With the `1.23` release, it is easier to use Weaviate with many open-source large language models (LLMs) such as Llama2-70b, CodeLlama-34b or Mistral-7B-Instruct.
# This module integrates Weaviate with the Anyscale service, which provides a hosted inference service for large language models.
# This allows Weaviate users to perform retrieval augmented generation (RAG) with open-source LLMs, without having to worry about the infrastructure required to run these models.

# Python client beta update
# The Weaviate Python client has been updated to support the new `1.23` features.
# This release also includes additional syntax changes to make the client more intuitive.

# Performance improvements
# Lazy shard loading allows you to start working with your data sooner.
# You can now enable an option to auto-limit available resources in Weaviate.

# Minor changes
# The `nodes` endpoint can be used to output information about the nodes in your cluster.
# This endpoint has been updated with a new `output` parameter that has a `minimal` default.

# Summary
# That's all from us - we hope you enjoy the new features and improvements in Weaviate `1.23`.
# This release is already available on WCS. So you can try it out yourself on a free sandbox, or by upgrading!
