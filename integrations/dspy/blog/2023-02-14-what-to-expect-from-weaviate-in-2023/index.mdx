---
title: What to expect from Weaviate in 2023
slug: what-to-expect-from-weaviate-in-2023
authors: [etienne]
date: 2023-02-14
tags: ['engineering']
image: ./img/hero.png
description: "Learn about the six pillars outlining how Weaviate will evolve in 2023."
---
![What to expect from Weaviate in 2023](./img/hero.png)

Comments:

* Introduction to the six pillars outlining how Weaviate will get even better in 2023
* Weaviate development is highly dynamic and the company and product have grown tremendously in 2022
* Weaviate usage numbers are through the roof and the company is working on improving the product based on user feedback and requests

In 2023, we will focus on six key areas to make Weaviate even better:

## The Six Pillars for 2023

### 1. Ingestion and Search Pipelines

* Weaviate has a strong and growing module ecosystem that gives users flexibility in how they use the product
* In early 2023, the company added the `generative-openai` module and plans to add more generative modules
* The proposed Pipe API will give users more flexibility in controlling arbitrary querying steps such as reading, re-ranking, summarizing, generating, and others
* The company also plans to give users more flexibility during ingestion time, such as extracting PDFs or applying stemming to BM25 and hybrid search

### 2. Beyond Billion Scale: Large-Scale Performance

* In 2022, the company published the Sphere Demo Dataset for Weaviate, which marked the first time (to their knowledge) that more than a billion objects and vectors were imported into Weaviate
* Dealing with ever-growing datasets is not only about being able to handle their size, but also about performance
* The first big step in this pillar will be the move towards a Native Roaring Bitmap Index, which can speed up filtered vector search by a factor of 1000 in the most extreme case
* The company is already thinking about the next steps, such as faster aggregations or new types of specialized indexes

### 3. Cloud Operations & Scaling

* In late 2022, the company introduced Replication to Weaviate, which made it easier to achieve a highly available setup and dynamically scale the setup to increase throughput
* In 2023, the company will focus on improving the cloud and operations experience by giving users more control over how to structure their workloads in a distributed setup and more flexibility to adapt to their ever-changing needs
* The company is also working on making the distributed cluster even more resilient

### 4. New Vector Indexes

* Last year, the company gave users a sneak peek into their Vector Indexing Research and this year they will be able to try out new vector indexes for themselves
* Weaviate has supported vector indexing with HNSW, which leads to best-in-class query times, but not every use case requires single-digit millisecond latencies
* The company will offer users not just one but two memory-saving options to index their vectors without sacrificing latency and throughput
* In early 2023, users will be able to use Product Quantization, a vector compression algorithm, in Weaviate and a fully disk-based solution will be released in late 2023

### 5. Improving our Client and Module Ecosystem

* So far, the company has discussed features related to Weaviate Core, the server in the user's setup
* But the Weaviate experience is more than that, modules allow users to integrate seamlessly with various embedding providers and the language clients make Weaviate accessible right from their application
* This year, the company will further improve both by introducing improved APIs on the client side, new modules, and improvements to existing modules

### 6. Community

* The most important pillar is the community, which includes both free, open-source users that self-host their Weaviate setup, as well as paid enterprise users and anyone using the company's Weaviate-as-a-Service offerings
* The company values the community's feedback and loves that they are part of shaping the future
* Last year, the company introduced a dynamic roadmap page that allows users to create and upvote their favorite feature requests

<br></br>

import WhatNext from '/_includes/what-next.mdx'

<WhatNext />

