---
title: Hybrid Search Explained
slug: hybrid-search-explained
authors: [erika]
date: 2023-01-03
tags: ['concepts', 'search']
image: ./img/hero.png
description: "Learn about the new hybrid search feature that enables you to combine dense and sparse vectors to deliver the best of both search methods."
---
![Hybrid search](./img/hero.png)

<!-- truncate -->

<h2 id="hybrid-search">Hybrid search</h2>

Hybrid search is a technique that combines multiple search algorithms to improve the accuracy and relevance of search results. It uses the best features of both keyword-based search algorithms with vector search techniques. By leveraging the strengths of different algorithms, it provides a more effective search experience for users.

The [Hybrid search](/developers/weaviate/api/graphql/search-operators#hybrid) feature was introduced in Weaviate 1.17. It uses sparse and dense vectors to represent the meaning and context of search queries and documents.

<h2 id="sparse-and-dense-vectors">Sparse and Dense Vectors</h2>

Sparse and dense vectors are calculated with distinct algorithms. Sparse vectors have mostly zero values with only a few non-zero values, while dense vectors mostly contain non-zero values. Sparse embeddings are generated from algorithms like [BM25](https://en.wikipedia.org/wiki/Okapi_BM25) and [SPLADE](https://arxiv.org/abs/2107.05720). Dense embeddings are generated from machine learning models like [GloVe](https://text2vec.org/glove.html) and [Transformers](https://huggingface.co/docs/transformers/index).

Note, the current implementation of hybrid search in Weaviate uses BM25/BM25F and vector search.

If you’re interested to learn about how dense vector indexes are built and optimized in Weaviate, check out this [article](/blog/why-is-vector-search-so-fast).

<h3 id="bm25">BM25</h3>

BM25 builds on the keyword scoring method [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) (Term-Frequency Inverse-Document Frequency) by taking the [Binary Independence Model](https://en.wikipedia.org/wiki/Binary_Independence_Model) from the IDF calculation and adding a normalization penalty that weighs a document’s length relative to the average length of all the documents in the database.

The image below presents the scoring calculation of BM25:
![BM25 calculation](./img/BM25-calculation.png) <div align="center"><i>Source: Wikipedia page on Okapi BM25</i></div>

The score of the document, query pair is determined by weighing the uniqueness of each keyword in the query relative to the collection of texts. BM25 contains additional static parameters, k1 and b that may help calibrate performance to particular datasets.

<h3 id="bm25f">BM25F</h3>

BM25F was also implemented in Weaviate `1.17`. BM25F is a variant of BM25 that allows multiple text fields per object to be given different weights in the ranking calculation. These weights are important for when fields in a document are more important than others. For example, a title may be given more weight than the abstract, since the title is sometimes more informative and concise. This type of weighting makes BM25F more flexible and customizable than BM25.

<h3 id="dense-vectors">Dense Vectors</h3>

Dense vectors represent information stored in a database; this includes text, images, and other types of data. These embeddings are generated from machine learning models that convert data to vectors. The vectors are densely packed with information and are mostly made up of non-zero values. The meaning of each value in the vector depends on the machine learning model that you used.

Vector databases, like [Weaviate](/developers/weaviate/), store these embeddings and calculate the distance between the two vectors. [Distance metrics](/blog/distance-metrics-in-vector-search) show how similar or dissimilar two vector embeddings are. The search query is converted to a vector, similar to the data vectors, and the distance value determines how close the vectors are.

<h2 id="hybrid-search-explained">Hybrid Search Explained</h2>

Hybrid search merges dense and sparse vectors together to deliver the best of both search methods. Generally speaking, dense vectors excel at understanding the context of the query, whereas sparse vectors excel at keyword matches. Consider the query, “How to catch an Alaskan Pollock”. The dense vector representation is able to disambiguate “catch” as meaning fishing rather than baseball or sickness. The sparse vector search will match the phrase “Alaskan Pollock” only. This example query shows where hybrid search combines the best of both sparse and dense vectors.

<h2 id="reciprocal-rank-fusion-rrf">Reciprocal Rank Fusion (RRF)</h2>

While researching hybrid search, we needed a way to combine the results of BM25 and dense vector search into a single ranked list. We came across a paper from Benham and Culpepper exploring rank fusion techniques. This paper analyzed seven strategies for combining the ranked results of two lists into a single ranking. We decided to start with the RRF score. The RRF score is calculated by taking the sum of the reciprocal rankings that is given from each list. By putting the rank of the document in the denominator, it penalizes the documents that are ranked lower in the list.

<p align="center"><img src="/img/blog/2023-01-03-hybrid-search-explained/RRF-calculation.png" alt="RRF Calculation" width="50%"/></p>
<div align="center"> <i> Source: Benham and Culpepper 2017 </i> </div>

Let's look at an example of this. We have three documents labeled `A`, `B`,
