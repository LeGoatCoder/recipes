---
title: Giving Auto-GPT Long-Term Memory with Weaviate
slug: autogpt-and-weaviate
authors: [erika, jp]
date: 2023-04-18
image: ./img/hero.png
tags: ['integrations']
description: "Learn about Auto-GPT and how to give it long-term memory with Weaviate!"
---

![autogpt and weaviate](./img/hero.png)

<!-- truncate -->

:::info Auto-GPT being re-factored
Edit (5/Jun/2023): Auto-GPT has [temporarily removed support for external vector stores as they refactor their code](https://github.com/Significant-Gravitas/Auto-GPT/blob/60ac0c4da15930d5e40af87fba6248ec37a951ee/BULLETIN.md?plain=1#L27).

We are working on re-introducing the integration. For now, please use this version (<https://github.com/Significant-Gravitas/Auto-GPT/tree/v0.3.1>) to use Auto-GPT with Weaviate.
:::

Auto-GPT is a popular open-source python project that harnesses the power of GPT-4 to complete various tasks autonomously. It takes GPT-4 one step further by enabling the model to run iteratively and complete tasks in a siloed fashion. It can write code, conduct market research, and even order pizza.

## What is Auto-GPT?

Auto-GPT has gotten a lot of attention lately, with the amount of stars jumping from 20k to 80k in a matter of days. Auto-GPT chains together “thoughts” and completes various tasks or assignments **autonomously**. It can write code and execute python scripts, conduct market research, and order pizza.

ChatGPT requires humans to prompt the large language model (LLM) by developing and refining the text prompt. Auto-GPT, on the other hand, is able to independently define objectives needed to complete the assigned task **without (or with reduced) human feedback and intervention**. This is because of its ability to chain together thoughts.

## How Auto-GPT Works

At the time of writing, Auto-GPT uses GPT-4 (or optionally, GPT-3.5) for text generation and GPT-3.5 for file storage and summarization. At configuration, Auto-GPT is given a list of tools such as a code executor, google search API, or a calculator. Additionally, it is possible to give Auto-GPT access to long-term memory via a vector database, such as Weaviate. Auto-GPT also has access to `skills` which are manifested as pre-configured prompts such as summarization.

Armed with these tools, Auto-GPT begins with a user query. For example, “Please write out a grocery list and create a recipe using each ingredient.” Auto-GPT takes this task and proposes an action plan to achieve the task. It will then review the results and make a refined plan. The ability to reason and refine its actions is what makes Auto-GPT so clever.

## Examples of Auto-GPT

People all over Twitter have shared multiple demos of what they’ve built with Auto-GPT. The possibilities are endless! Here are a few popular examples:

- Conducting market research and finding competitors
- Creating an app and installing dependencies
- Ordering pizza on Domino's website

## How to use Auto-GPT with Weaviate

Auto-GPT has both a short-term and long-term memory. By connecting to a vector database, like Weaviate, you enable the application to retrieve specific data. This extension is great if you’re asking Auto-GPT to complete a task that it wasn’t trained on.

Here is the [codebase](https://github.com/Significant-Gravitas/Auto-GPT/blob/v0.3.1/autogpt/memory/weaviate.py) to see how Weaviate is integrated in Auto-GPT.

The easiest way to use Weaviate with Auto-GPT is with a WCS instance. Create a Sandbox instance by following [these steps](https://weaviate.io/developers/wcs/quickstart#create-a-weaviate-cluster), and install Auto-GPT using the latest instructions from the repo, with the following notes in mind:

- At the time of writing, it suggested using the [latest stable release](https://github.com/Significant-Gravitas/Auto-GPT/releases/latest) only, rather than the `master` branch.
- We recommend running Auto-GPT in a Docker container so that it runs in a safer, sandboxed environment.
- If you intend to run Auto-GPT directly from your device, rather than in a Docker container, we suggest installing the required libraries into a virtual environment, rather than to your system Python.

During installation, edit the below variables in the Auto-GPT `.env` file based on the following:




And then, you can start Auto-GPT. You can run it directly on your device, or within a Docker container. To run it directly, run:




Or run the following to start it within a Docker container:




The above steps will allow Auto-GPT to use the WCS instance as the memory backend, allowing it to store and retrieve information as required.

We note using a local instance of We
