# This is a markdown file explaining the concept of vector search and how it is implemented in Weaviate, a vector database.

# The file starts by explaining the 'wow' factor of vector search, which is its ability to perform semantic searches on large datasets (e.g. 28 million Wikipedia paragraphs) in a matter of milliseconds.

# It then goes on to explain what a vector search is and how it differs from traditional keyword searches. A vector search is based on the semantic meaning of the query and data, rather than exact keyword matches.

# To perform a vector search, the data is first indexed based on vector embeddings, which are numerical representations of the data that capture its meaning and context. These vector embeddings are predicted by machine learning models.

# When a query is made, the query is also converted into a vector and the task of the vector database is to identify and retrieve a list of vectors that are closest to the given vector of the query.

# The file then explains the concept of k-nearest neighbors (kNN) and how it can be used to find similar vectors. However, kNN is computationally expensive and does not scale well with large datasets.

# Instead, vector databases use Approximate Nearest Neighbor (ANN) algorithms, which trade off a bit of accuracy for a huge gain in speed. ANN algorithms maintain good performance on large-scale datasets and allow for the configuration of the balance between recall, latency, throughput, and import time.

# The file then gives examples of ANN algorithms, such as trees (e.g. ANNOY), proximity graphs (e.g. HNSW), clustering (e.g. FAISS), hashing (e.g. LSH), and vector compression (e.g. PQ or SCANN).

# Weaviate, a vector database, uses a custom implementation of HNSW and offers ultra-fast queries with high recall rates, high throughput, and low latency.

# The file ends with a recap of the key points and provides resources for learning more about vector databases and Weaviate.

